{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {}\n",
    "hyperparameters[\"access_token\"] =  \"hf_xxxx\" # update the access token from hf\n",
    "hyperparameters[\"model_name\"] = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "hyperparameters[\"tp_size\"] = 8\n",
    "hyperparameters[\"pp_size\"] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_s3_uri = \"s3://\" + sagemaker_session_bucket + \"/neuronx_llama_experiment\"\n",
    "# we will use the sagemaker s3 checkpoints mechanism since we need read/write access to the paths.\n",
    "hyperparameters[\"output_dir\"] = \"/opt/ml/checkpoints/llama70b_weights\"\n",
    "hyperparameters[\"checkpoint-dir\"] = '/opt/ml/checkpoints'\n",
    "hyperparameters[\"convert_from_full_model\"] = \"\"\n",
    "hyperparameters[\"n_layers\"] = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_image = \"763104351884.dkr.ecr.us-east-2.amazonaws.com/pytorch-training-neuronx:1.13.1-neuronx-py310-sdk2.17.0-ubuntu20.04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "# Need to check if this works on multinode with torchrun.\n",
    "estimator = PyTorch(\n",
    "    base_job_name=\"neuronx-llama-download-model-weights\",\n",
    "    source_dir=\"./scripts\",\n",
    "    entry_point=\"convert_checkpoints.py\",\n",
    "    role=role,\n",
    "    image_uri=docker_image,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.trn1.32xlarge\",\n",
    "    sagemaker_session=sess,\n",
    "    volume_size=1024,\n",
    "    hyperparameters=hyperparameters,\n",
    "    debugger_hook_config=False,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "    checkpoint_local_path=hyperparameters[\"checkpoint-dir\"],\n",
    "    disable_output_compression=True,\n",
    "    keep_alive_period_in_seconds=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
