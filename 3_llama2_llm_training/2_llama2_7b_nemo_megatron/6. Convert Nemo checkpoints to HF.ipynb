{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Nemo checkpoint to Huggingace format for Inferencing\n",
    "\n",
    "The output from the training job is saved as nemo checkpoint. In this notebook we will convert the nemo checkpoint into a .pt weights file which can be used for inferencing.\n",
    "\n",
    "To begin with we will retrieve the path for the checkpoint from the model output and also path to llama7b config file, this can be retreived from Notebook 3. Prepare Dataset.ipynb job output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_checkpoint_path = \"<Add s3 path from Training Job checkpoints>\" # Checkpoint is saved as part of Notebook 5\n",
    "path_to_llama_config = \"s3://<pathto llama config>/config.json\"  # this is saved as part of Notebook 3 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the docker image URL stored in step 1\n",
    "%store -r docker_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {}\n",
    "hyperparameters[\"path_to_checkpoints\"] = \"/opt/ml/input/data/checkpoint\"\n",
    "hyperparameters[\"config_file\"] = \"/opt/ml/input/data/config/config.json\"\n",
    "hyperparameters[\"output_path\"] = \"/opt/ml/model\"\n",
    "hyperparameters[\"is_xser\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "# Need to check if this works on multinode with torchrun.\n",
    "estimator = PyTorch(\n",
    "    base_job_name=\"nemo-megatron-data-prep\",\n",
    "    source_dir=\"./scripts\",\n",
    "    entry_point=\"convert_nemo_checkpoint_to_hf.py\",\n",
    "    role=role,\n",
    "    image_uri=docker_image,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    sagemaker_session=sess,\n",
    "    volume_size=512,\n",
    "    hyperparameters=hyperparameters,\n",
    "    debugger_hook_config=False,\n",
    "    disable_output_compression=True,\n",
    "    keep_alive_period_in_seconds=600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({\"checkpoint\":nemo_checkpoint_path,\"config\":path_to_llama_config})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
