{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert HF weights to Nemo format\n",
    "\n",
    "In order to use a pretrained model weights we need to convert HF Weights into nemo checkpoint. This notebook helps in converting the HF pretrained weights to Nemo checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the docker image URL stored in step 1\n",
    "%store -r docker_image \n",
    "\n",
    "use_fsx = False # set this to true and check other fsx parameters to use FSxL for the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive the FSX details from Store Magic \n",
    "\n",
    "if use_fsx:\n",
    "    #retrive fsx details\n",
    "    %store -r fsx_id\n",
    "    %store -r sec_group\n",
    "    %store -r private_subnet_id\n",
    "    %store -r fsx_mount\n",
    "    %store -r fsx_file_system_path\n",
    "else:\n",
    "    use_fsx = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {}\n",
    "hyperparameters[\"access_token\"] =  \"hf_xxxxx\" # update the access token from hf\n",
    "hyperparameters[\"model_name\"] = \"meta-llama/Llama-2-7b-hf\"\n",
    "hyperparameters[\"tp_degree\"] = 8\n",
    "hyperparameters[\"pp_degree\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup fsx config for data channels\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "if use_fsx:\n",
    "    FS_ID = fsx_id # FSX ID\n",
    "    FS_BASE_PATH = \"/\" + fsx_mount + \"/\" + fsx_file_system_path # Path in the filesystem that needs to be mounted\n",
    "    SUBNET_ID = private_subnet_id # Subnet to launch SM jobs in\n",
    "    SEC_GRP = [sec_group]\n",
    "\n",
    "    fsx_train_input = FileSystemInput(\n",
    "        file_system_id=FS_ID,\n",
    "        file_system_type='FSxLustre',\n",
    "        directory_path=FS_BASE_PATH + \"/nemo_llama\",\n",
    "        file_system_access_mode=\"rw\"\n",
    "    )\n",
    "    hyperparameters[\"output_path\"] = \"/opt/ml/input/data/train/llama7b_weights\"\n",
    "    data_channels = {\"train\": fsx_train_input}\n",
    "\n",
    "else:\n",
    "    checkpoint_s3_uri = \"s3://\" + sagemaker_session_bucket + \"/nemo_llama_experiment\"\n",
    "    # we will use the sagemaker s3 checkpoints mechanism since we need read/write access to the paths.\n",
    "    hyperparameters[\"output_path\"] = \"/opt/ml/checkpoints/llama7b_weights\"\n",
    "    hyperparameters[\"checkpoint-dir\"] = '/opt/ml/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "# Need to check if this works on multinode with torchrun.\n",
    "estimator = PyTorch(\n",
    "    base_job_name=\"nemo-megatron-data-prep\",\n",
    "    source_dir=\"./scripts\",\n",
    "    entry_point=\"convert_hf_checkpoint_to_nemo.py\",\n",
    "    role=role,\n",
    "    image_uri=docker_image,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.trn1.2xlarge\",\n",
    "    sagemaker_session=sess,\n",
    "    volume_size=512,\n",
    "    hyperparameters=hyperparameters,\n",
    "    debugger_hook_config=False,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri if not use_fsx else None,\n",
    "    checkpoint_local_path=hyperparameters[\"checkpoint-dir\"] if not use_fsx else None,\n",
    "    disable_output_compression=True,\n",
    "    subnets = [SUBNET_ID] if use_fsx else None, # Give SageMaker Training Jobs access to FSx resources in your Amazon VPC\n",
    "    security_group_ids=SEC_GRP if use_fsx else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_fsx:\n",
    "    estimator.fit(data_channels)\n",
    "else:\n",
    "    estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above job will store the model in the s3 bucket specified."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
