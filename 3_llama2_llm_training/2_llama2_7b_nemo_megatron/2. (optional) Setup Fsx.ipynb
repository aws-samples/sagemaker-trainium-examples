{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9275057",
   "metadata": {},
   "source": [
    "## SageMaker training with FSx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed23fa2",
   "metadata": {},
   "source": [
    "If you are training on a multinode cluster its recommended to use FSx for Lustre for storing and retrieving data / checkpoints.This sample shows how to:\n",
    "\n",
    "- Setup FSx\n",
    "- Associate data in S3 with FSx\n",
    "- Tear down the infrastructure\n",
    "\n",
    "**Please make sure the CIDR block in setup/cfn-nlp.yaml does not conflict with your existing VPC. You can also change FSx storage (currently set at 1.2 TB) depending on your data sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import boto3\n",
    "\n",
    "# Inputs\n",
    "region = \"us-west-2\"  # update this if your region is different\n",
    "region_az = \"us-west-2d\"  # customize this as needed. Your FSx will be set up in a subnet in this AZ\n",
    "cfn_stack_name = 'fsx-training-trn-stack'  # cloudformation stack name\n",
    "\n",
    "\n",
    "# Clients\n",
    "cfn_client = boto3.client(\"cloudformation\", region_name=region)\n",
    "fsx_client = boto3.client(\"fsx\", region_name=region)\n",
    "\n",
    "\n",
    "s3_data_bucket = 's3://bucket_name'\n",
    "s3_data_train_prefix = 'dataset_nemo'  # s3 training data set\n",
    "\n",
    "s3_data_model_prefix = 'model_dir' # s3 path to save model\n",
    "s3_data_checkpoint_prefix = 'checkpoint_dir'  # s3 path to save model checkpoints\n",
    "fsx_file_system_path = 'fsxneuron'  # this is file system path on FSx for the data, can be anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a6674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup infrastructure using CloudFormation\n",
    "with open(\"setup/cfn-nlp.yaml\", \"r\") as f:\n",
    "    template_body = f.read()\n",
    "    \n",
    "create_stack_response = cfn_client.create_stack(\n",
    "    StackName=cfn_stack_name,\n",
    "    TemplateBody=template_body,\n",
    "    Parameters=[\n",
    "        {\n",
    "            'ParameterKey': 'AZ',\n",
    "            'ParameterValue': region_az\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "create_stack_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5800b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wait for stack to be created, it takes ~10 minutes to complete.\n",
    "stack_id = create_stack_response['StackId']\n",
    "\n",
    "while True:\n",
    "    response = cfn_client.describe_stacks(\n",
    "        StackName=stack_id\n",
    "    )\n",
    "    status = response['Stacks'][0]['StackStatus']\n",
    "    if status== \"CREATE_IN_PROGRESS\":\n",
    "        print(\"Create in progress. Waiting..\")\n",
    "        time.sleep(30)\n",
    "    elif status==\"CREATE_COMPLETE\":\n",
    "        print(\"Stack created!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Error creating stack - check the CFN console\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stack outputs\n",
    "describe_response = cfn_client.describe_stacks(\n",
    "    StackName=stack_id\n",
    ")\n",
    "\n",
    "outputs = describe_response['Stacks'][0]['Outputs']\n",
    "\n",
    "for output in outputs:\n",
    "    if output['OutputKey'] == 'sg':\n",
    "        sec_group = output['OutputValue']\n",
    "    elif output['OutputKey'] == 'outputfsx':\n",
    "        fsx_id = output['OutputValue']\n",
    "    elif output['OutputKey'] == 'privatesubnet':\n",
    "        private_subnet_id = output['OutputValue']\n",
    "        \n",
    "fsx_response = fsx_client.describe_file_systems(\n",
    "    FileSystemIds=[fsx_id]\n",
    ")\n",
    "\n",
    "fsx_mount = fsx_response['FileSystems'][0]['LustreConfiguration']['MountName']\n",
    "\n",
    "print(\"FSx ID:\", fsx_id)\n",
    "print(\"Security Group ID:\", sec_group)\n",
    "print(\"Private Subnet ID:\", private_subnet_id)\n",
    "print(\"FSx Mount path:\", fsx_mount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0469bc4",
   "metadata": {},
   "source": [
    "### Store fsx details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937feaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store fsx_id\n",
    "%store sec_group\n",
    "%store private_subnet_id\n",
    "%store fsx_mount\n",
    "%store fsx_file_system_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147f75ab",
   "metadata": {},
   "source": [
    "### Create Data Repository Association (DRA) for S3 access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data repository association with S3 to load data\n",
    "# and persist changes back to S3 to save training artifacts\n",
    "\n",
    "fsx_s3_response = fsx_client.create_data_repository_association(\n",
    "    FileSystemId=fsx_id,\n",
    "    FileSystemPath=f\"/{fsx_file_system_path}\",\n",
    "    DataRepositoryPath=s3_data_bucket,\n",
    "    BatchImportMetaDataOnCreate=True,\n",
    "    S3={\n",
    "        \"AutoImportPolicy\": {\n",
    "            \"Events\": ['NEW', 'CHANGED', 'DELETED']\n",
    "        },\n",
    "         \"AutoExportPolicy\": {\n",
    "            \"Events\": ['NEW', 'CHANGED', 'DELETED']\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "fsx_s3_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46899a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wait for association to be complete\n",
    "while True:\n",
    "    fsx_s3_assoc = fsx_client.describe_data_repository_associations(\n",
    "        AssociationIds=[fsx_s3_response['Association']['AssociationId']]\n",
    "    )\n",
    "    fsx_status = fsx_s3_assoc['Associations'][0]['Lifecycle']\n",
    "\n",
    "    if fsx_status== \"CREATING\":\n",
    "        print(\"Create in progress. Waiting..\")\n",
    "        time.sleep(30)\n",
    "    elif fsx_status==\"AVAILABLE\":\n",
    "        print(\"FSx - S3 association complete!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Error creating the association, with status\", fsx_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3050cdd4",
   "metadata": {},
   "source": [
    "### Clean up resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ced56",
   "metadata": {},
   "source": [
    "You can tear down the CloudFormation stack to delete the VPC and associated resources, and the FSx file system to avoid incurring costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a3cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the stack\n",
    "\n",
    "delete_response = cfn_client.delete_stack(\n",
    "    StackName=stack_id\n",
    ")\n",
    "\n",
    "delete_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fbe2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arunpy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
